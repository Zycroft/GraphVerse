{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install git+https://github.com/ParkerWilliams/GraphVerse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import pandas as pd\n",
    "import math\n",
    "import random\n",
    "\n",
    "from graphverse.graph.graph_generation import generate_random_graph, calculate_edge_density\n",
    "from graphverse.graph.rules import AscenderRule, DescenderRule, EvenRule, OddRule\n",
    "from graphverse.graph.rules import define_ascenders, define_descenders, define_evens_odds\n",
    "from graphverse.data.preparation import prepare_training_data\n",
    "from graphverse.llm.training import train_model\n",
    "from graphverse.llm.evaluation import evaluate_model\n",
    "\n",
    "def main():\n",
    "    # Generate graph\n",
    "    n = 1000  # Number of vertices\n",
    "    c = 1.5   # Constant factor\n",
    "    G = generate_random_graph(n)\n",
    "\n",
    "    # Print some information about the graph\n",
    "    print(f\"Number of nodes: {G.number_of_nodes()}\")\n",
    "    print(f\"Number of edges: {G.number_of_edges()}\")\n",
    "    print(f\"Is strongly connected: {nx.is_strongly_connected(G)}\")\n",
    "    print(f\"Is wealky connected: {nx.is_weakly_connected(G)}\")\n",
    "\n",
    "    # Print the probability distribution for a few nodes\n",
    "    for node in range(min(5, n)):\n",
    "      print(f\"\\nProbability distribution for node {node}:\")\n",
    "    for u, v, data in G.out_edges(node, data=True):\n",
    "        print(f\"  Edge ({u}, {v}): {data['probability']:.4f}\")\n",
    "\n",
    "    # Define rule sets\n",
    "    ascenders = define_ascenders(G, n)\n",
    "    descenders = define_descenders(G, n)\n",
    "    evens, odds = define_evens_odds(G, n)\n",
    "\n",
    "    # Create rule tuple\n",
    "    rules = (\n",
    "    AscenderRule(ascenders),\n",
    "    DescenderRule(descenders),\n",
    "    EvenRule(evens),\n",
    "    OddRule(odds)\n",
    ")\n",
    "\n",
    "    # Prepare training data\n",
    "    training_data, vocab = prepare_training_data(G, num_samples=1000, min_length=10, max_length=50, rules=rules)\n",
    "\n",
    "    # Train the model\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = train_model(training_data, vocab, epochs=1, batch_size=32, learning_rate=0.001, device=device)\n",
    "\n",
    "    # Evaluate the model\n",
    "    max_corpus_length = training_data.size(1)  # Get the maximum sequence length\n",
    "    evaluation_results = evaluate_model(model, G, vocab, num_samples=10000,\n",
    "                                        min_start_length=1, max_start_length=int(0.1 * max_corpus_length), rules=rules)\n",
    "\n",
    "    # Analyze results\n",
    "    df_results = pd.DataFrame(evaluation_results)\n",
    "\n",
    "    print(\"\\nEvaluation Results:\")\n",
    "    print(f\"Average rule violations: {df_results['rule_violations'].mean():.2f}\")\n",
    "    print(f\"Average generated walk length: {df_results['generated_length'].mean():.2f}\")\n",
    "\n",
    "    # Optional: Save results to a CSV file\n",
    "    df_results.to_csv('evaluation_results.csv', index=False)\n",
    "    print(\"Detailed results saved to 'evaluation_results.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 1000\n",
      "Number of edges: 6901\n",
      "Is strongly connected: True\n",
      "Is wealky connected: True\n",
      "\n",
      "Probability distribution for node 0:\n",
      "\n",
      "Probability distribution for node 1:\n",
      "\n",
      "Probability distribution for node 2:\n",
      "\n",
      "Probability distribution for node 3:\n",
      "\n",
      "Probability distribution for node 4:\n",
      "  Edge (4, 158): 0.0870\n",
      "  Edge (4, 755): 0.4583\n",
      "  Edge (4, 466): 0.4546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zycro\\anaconda3\\envs\\cuda1\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "c:\\Users\\zycro\\anaconda3\\envs\\cuda1\\lib\\site-packages\\torch\\nn\\functional.py:5560: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1, Loss: 6.7603\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'488'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[2], line 55\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[0;32m     54\u001b[0m max_corpus_length \u001b[38;5;241m=\u001b[39m training_data\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Get the maximum sequence length\u001b[39;00m\n\u001b[1;32m---> 55\u001b[0m evaluation_results \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mmin_start_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_start_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmax_corpus_length\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrules\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrules\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# Analyze results\u001b[39;00m\n\u001b[0;32m     59\u001b[0m df_results \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(evaluation_results)\n",
      "File \u001b[1;32mc:\\Users\\zycro\\OneDrive\\Documents\\Python\\_GraphVerseFork\\GraphVerse\\graphverse\\llm\\evaluation.py:12\u001b[0m, in \u001b[0;36mevaluate_model\u001b[1;34m(model, graph, vocab, num_samples, min_start_length, max_start_length, rules)\u001b[0m\n\u001b[0;32m     10\u001b[0m start_length \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mrandint(min_start_length, max_start_length)\n\u001b[0;32m     11\u001b[0m start_sequence \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mchoices(\u001b[38;5;28mlist\u001b[39m(graph\u001b[38;5;241m.\u001b[39mnodes()), k\u001b[38;5;241m=\u001b[39mstart_length)\n\u001b[1;32m---> 12\u001b[0m generated_walk \u001b[38;5;241m=\u001b[39m \u001b[43mseed_walk\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_sequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvocab\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvocab\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m rule_violations \u001b[38;5;241m=\u001b[39m count_rule_violations(generated_walk, graph, rules)\n\u001b[0;32m     16\u001b[0m results\u001b[38;5;241m.\u001b[39mappend({\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstart_length\u001b[39m\u001b[38;5;124m'\u001b[39m: start_length,\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenerated_length\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mlen\u001b[39m(generated_walk),\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrule_violations\u001b[39m\u001b[38;5;124m'\u001b[39m: rule_violations\n\u001b[0;32m     20\u001b[0m })\n",
      "File \u001b[1;32mc:\\Users\\zycro\\OneDrive\\Documents\\Python\\_GraphVerseFork\\GraphVerse\\graphverse\\llm\\token_generation.py:9\u001b[0m, in \u001b[0;36mseed_walk\u001b[1;34m(model, start_sequence, max_length, vocab, device)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(current_sequence) \u001b[38;5;241m<\u001b[39m max_length:\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m----> 9\u001b[0m         input_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([vocab\u001b[38;5;241m.\u001b[39mtoken2idx[\u001b[38;5;28mstr\u001b[39m(token)] \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m current_sequence])\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     10\u001b[0m         output \u001b[38;5;241m=\u001b[39m model(input_tensor)\n\u001b[0;32m     11\u001b[0m         next_token_idx \u001b[38;5;241m=\u001b[39m output[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :]\u001b[38;5;241m.\u001b[39margmax()\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32mc:\\Users\\zycro\\OneDrive\\Documents\\Python\\_GraphVerseFork\\GraphVerse\\graphverse\\llm\\token_generation.py:9\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(current_sequence) \u001b[38;5;241m<\u001b[39m max_length:\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m----> 9\u001b[0m         input_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[43mvocab\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoken2idx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m current_sequence])\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     10\u001b[0m         output \u001b[38;5;241m=\u001b[39m model(input_tensor)\n\u001b[0;32m     11\u001b[0m         next_token_idx \u001b[38;5;241m=\u001b[39m output[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :]\u001b[38;5;241m.\u001b[39margmax()\u001b[38;5;241m.\u001b[39mitem()\n",
      "\u001b[1;31mKeyError\u001b[0m: '488'"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
